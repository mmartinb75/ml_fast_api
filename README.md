游빍 C칩mo levantar el servidor FastAPI

  El servidor est치 definido en ml_server_2.py y expone endpoints para subir un modelo y hacer predicciones.

游댢 Requisitos

  Instala las dependencias necesarias:
  
  `pip install fastapi uvicorn scikit-learn pandas numpy`
  
游 Lanzar el servidor

  Desde la ra칤z del proyecto (donde est칠 ml_server_2.py):
  
  `fastapi dev ml_server_2.py`
  
  Esto abrir치 el servidor en http://127.0.0.1:8000. La documentaci칩n interactiva est치 disponible en:
  http://127.0.0.1:8000/docs
  
游닋 Endpoints principales

  POST /upload_model/: subir archivos .pkl del preprocesador, filtro y modelo.
  
  POST /predict/: realizar predicciones normales.
  
  POST /predict_w_intervals/: realizar predicciones con intervalos de confianza.
  
  Los tres archivos .pkl deben ser cargados antes de realizar predicciones.
